# üìã Plan de Mejora del Sistema de Resumen - SIGRAA
## Plan Senior Developer | Noviembre 2025

---

## üéØ Objetivo

Transformar el sistema de resumen de **b√°sico (5 l√≠neas)** a **robusto y acad√©mico** (hasta 8+ p√°ginas), capturando todos los puntos importantes de documentos cient√≠ficos.

---

## üî¥ Problemas Actuales Identificados

### Sistema Actual
```python
max_input_chars = 12,000     # Solo ~3-4 p√°ginas
max_pages = 5                 # M√°ximo 5 p√°ginas procesadas
max_sentences = 5             # Solo 5 oraciones
Groq prompt = "5 bullet points, each under 35 words"  # ~175 palabras total
```

### Limitaciones Cr√≠ticas

1. ‚ùå **Solo procesa 12k caracteres** ‚Üí Documentos de 20 p√°ginas tienen ~40-50k caracteres
2. ‚ùå **Resumen de 5 oraciones** ‚Üí Insuficiente para capturar ideas complejas
3. ‚ùå **No extrae estructura del documento** ‚Üí Pierde secciones importantes
4. ‚ùå **No hay niveles de detalle** ‚Üí Un solo tipo de resumen
5. ‚ùå **Procesamiento lineal simple** ‚Üí No usa t√©cnicas avanzadas (map-reduce, chunking)
6. ‚ùå **Sin contexto entre secciones** ‚Üí Pierde hilos argumentativos

### Impacto en Usuarios

- **Investigadores**: No pueden identificar contribuciones reales
- **Estudiantes**: Pierden metodolog√≠as y resultados clave
- **Docentes**: No ven estructura pedag√≥gica completa

---

## üèóÔ∏è Arquitectura Propuesta: Sistema de Resumen Multinivel

### Nivel 1: Resumen Ejecutivo (Quick)
**Objetivo**: Vista r√°pida del documento
**Longitud**: 1 p√°gina (~500 palabras)
**Tiempo**: ~30 segundos

**Contenido**:
- T√≠tulo y autores
- Problema de investigaci√≥n (2 p√°rrafos)
- Metodolog√≠a principal (1 p√°rrafo)
- Hallazgos clave (3-5 bullet points)
- Conclusi√≥n principal (1 p√°rrafo)

---

### Nivel 2: Resumen Detallado (Standard)
**Objetivo**: Comprensi√≥n profunda sin leer todo
**Longitud**: 3-4 p√°ginas (~1,500-2,000 palabras)
**Tiempo**: ~2-3 minutos

**Contenido**:
- **Introducci√≥n**:
  - Contexto y motivaci√≥n (2 p√°rrafos)
  - Gap en literatura (1 p√°rrafo)
  - Objetivos e hip√≥tesis (bullets)

- **Metodolog√≠a**:
  - Dise√±o del estudio (1-2 p√°rrafos)
  - Participantes/Muestra (1 p√°rrafo)
  - Instrumentos y procedimientos (bullets)
  - An√°lisis de datos (1 p√°rrafo)

- **Resultados**:
  - Hallazgos principales por objetivo (secciones)
  - Datos cuantitativos relevantes (bullets con n√∫meros)
  - Hallazgos secundarios (breve)

- **Discusi√≥n y Conclusiones**:
  - Interpretaci√≥n de resultados (2 p√°rrafos)
  - Implicaciones pr√°cticas (bullets)
  - Limitaciones (bullets)
  - Futuras investigaciones (bullets)

---

### Nivel 3: Resumen Exhaustivo (Deep)
**Objetivo**: Extracci√≥n m√°xima de conocimiento
**Longitud**: 6-10 p√°ginas (~3,000-5,000 palabras)
**Tiempo**: ~5-10 minutos

**Contenido**:
- Todo lo de Nivel 2, m√°s:
- **Marco Te√≥rico Completo**:
  - Teor√≠as fundamentales citadas
  - Modelos y frameworks utilizados
  - Definiciones de conceptos clave

- **Metodolog√≠a Detallada**:
  - Justificaci√≥n metodol√≥gica
  - Procedimientos paso a paso
  - Instrumentos de medici√≥n (descripciones)
  - Criterios de inclusi√≥n/exclusi√≥n
  - Consideraciones √©ticas

- **Resultados Exhaustivos**:
  - Todos los hallazgos (principales y secundarios)
  - Tablas y figuras descritas textualmente
  - An√°lisis estad√≠sticos completos
  - Casos particulares o outliers

- **Discusi√≥n Profunda**:
  - Comparaci√≥n con estudios previos (por autor)
  - Explicaciones alternativas consideradas
  - Fortalezas metodol√≥gicas
  - Implicaciones te√≥ricas y pr√°cticas expandidas

- **Ap√©ndices**:
  - Definiciones de t√©rminos t√©cnicos
  - Referencias clave mencionadas
  - Ecuaciones o f√≥rmulas importantes

---

## üõ†Ô∏è Implementaci√≥n T√©cnica

### Fase 1: Extracci√≥n Inteligente de Secciones

```python
class DocumentStructureExtractor:
    """Identifica y extrae secciones del documento."""

    SECTION_PATTERNS = {
        'abstract': r'(abstract|resumen)',
        'introduction': r'(introduction|introducci√≥n|background)',
        'literature': r'(literature review|estado del arte|marco te√≥rico)',
        'methodology': r'(methodology|methods|m√©todos|metodolog√≠a)',
        'results': r'(results|resultados|findings|hallazgos)',
        'discussion': r'(discussion|discusi√≥n)',
        'conclusions': r'(conclusions|conclusiones|conclusion)',
        'references': r'(references|bibliograf[i√≠]a|referencias)',
    }

    def extract_sections(self, pdf_path: str) -> Dict[str, str]:
        """
        Extrae secciones identificadas del PDF.
        Returns: {section_name: text_content}
        """
        pass

    def identify_section_boundaries(self, pages: List[str]) -> Dict[str, Tuple[int, int]]:
        """
        Identifica inicio y fin de cada secci√≥n.
        Returns: {section_name: (start_page, end_page)}
        """
        pass
```

**Ventajas**:
- ‚úÖ Procesa documento por secciones l√≥gicas
- ‚úÖ Mantiene contexto de cada parte
- ‚úÖ Permite res√∫menes espec√≠ficos por secci√≥n

---

### Fase 2: Procesamiento por Chunks con Map-Reduce

```python
class ChunkedSummarizer:
    """Procesa documentos largos en chunks con contexto."""

    def __init__(self):
        self.chunk_size = 3000  # tokens
        self.overlap = 300       # overlap entre chunks

    def summarize_document(
        self,
        full_text: str,
        level: str = "detailed",
        sections: Optional[Dict[str, str]] = None
    ) -> str:
        """
        Map-Reduce summarization:
        1. MAP: Resume cada chunk individualmente
        2. REDUCE: Combina res√∫menes parciales en uno coherente
        """

        # PASO 1: Dividir en chunks con overlap
        chunks = self._create_overlapping_chunks(full_text)

        # PASO 2: MAP - Resumir cada chunk
        chunk_summaries = []
        for i, chunk in enumerate(chunks):
            summary = self._summarize_chunk(
                chunk,
                chunk_number=i,
                total_chunks=len(chunks),
                level=level
            )
            chunk_summaries.append(summary)

        # PASO 3: REDUCE - Combinar res√∫menes
        final_summary = self._merge_summaries(
            chunk_summaries,
            level=level,
            sections=sections
        )

        return final_summary

    def _create_overlapping_chunks(self, text: str) -> List[str]:
        """Crea chunks con overlap para mantener contexto."""
        pass

    def _summarize_chunk(
        self,
        chunk: str,
        chunk_number: int,
        total_chunks: int,
        level: str
    ) -> str:
        """Resume un chunk con contexto de posici√≥n."""
        pass

    def _merge_summaries(
        self,
        summaries: List[str],
        level: str,
        sections: Optional[Dict[str, str]]
    ) -> str:
        """Combina res√∫menes parciales de forma coherente."""
        pass
```

**Ventajas**:
- ‚úÖ Procesa documentos de cualquier tama√±o
- ‚úÖ Overlap mantiene continuidad
- ‚úÖ Map-reduce escala a m√∫ltiples documentos

---

### Fase 3: Prompts Mejorados para Groq

```python
PROMPTS_BY_LEVEL = {
    "executive": """You are an expert research analyst. Create a 1-page EXECUTIVE SUMMARY.

DOCUMENT:
{text}

FORMAT YOUR SUMMARY AS:
# Executive Summary

## Research Problem
[2 paragraphs: What problem does this research address? Why is it important?]

## Methodology
[1 paragraph: What approach was used to investigate the problem?]

## Key Findings
- [Finding 1 with supporting data]
- [Finding 2 with supporting data]
- [Finding 3 with supporting data]

## Main Conclusion
[1 paragraph: What is the main takeaway?]

Use clear, academic language. Be specific with numbers and results.
Target length: 500 words.""",

    "detailed": """You are an expert research analyst. Create a DETAILED SUMMARY (3-4 pages).

SECTION: {section_name}
CONTENT:
{text}

FORMAT YOUR SUMMARY AS:
# Detailed Summary - {section_name}

## Context and Background
[2-3 paragraphs explaining the background, motivation, and research gap]

## Objectives and Research Questions
- [Objective 1]
- [Objective 2]
- [Hypothesis if applicable]

## Methodology
### Study Design
[1-2 paragraphs on research design]

### Sample and Participants
[1 paragraph on who/what was studied]

### Data Collection
- [Instrument 1: description]
- [Instrument 2: description]

### Analysis Methods
[1 paragraph on how data was analyzed]

## Key Results
### Main Findings
[2-3 paragraphs on primary results with specific numbers/data]

### Secondary Findings
- [Finding 1]
- [Finding 2]

## Discussion
[2 paragraphs interpreting results]

## Implications
- [Practical implication 1]
- [Practical implication 2]

## Limitations
- [Limitation 1]
- [Limitation 2]

Be thorough and academic. Include all important details.
Target length: 1,500-2,000 words.""",

    "exhaustive": """You are an expert research analyst. Create an EXHAUSTIVE SUMMARY (8-10 pages).

DOCUMENT SECTION: {section_name}
FULL CONTENT:
{text}

YOUR TASK:
Extract EVERY important piece of information. This summary should allow someone to understand the research deeply without reading the original.

FORMAT:
# Exhaustive Analysis - {section_name}

## Theoretical Framework
[Detailed explanation of theories, models, and frameworks]

### Key Concepts
- **Concept 1**: [Definition and relevance]
- **Concept 2**: [Definition and relevance]

## Literature Review
[Comprehensive overview of related research cited]

### Previous Studies
[Author 1 (Year)]: [Key findings and how they relate]
[Author 2 (Year)]: [Key findings and how they relate]

## Methodology (Comprehensive)
### Epistemological Approach
[Paragraph on research paradigm]

### Study Design
[Detailed justification and description]

### Sample
- **Population**: [Description]
- **Sample size**: [Number and justification]
- **Sampling method**: [Description]
- **Inclusion criteria**: [List]
- **Exclusion criteria**: [List]

### Instruments
[Detailed description of each measurement instrument]

### Procedures
[Step-by-step description of what was done]

### Ethical Considerations
[Description of ethical protocols]

### Data Analysis
[Comprehensive description of statistical/qualitative methods]

## Results (Complete)
### Descriptive Statistics
[All relevant descriptive data]

### Main Findings by Research Question
**RQ1**: [Finding with full details]
**RQ2**: [Finding with full details]

### Statistical Results
[All significant statistical tests with values]

### Tables and Figures
[Textual description of all tables/figures]

### Unexpected Findings
[Description of any unexpected results]

## Discussion (In-Depth)
### Interpretation of Results
[Thorough interpretation]

### Comparison with Previous Research
[Detailed comparison with literature]

### Alternative Explanations
[Discussion of other possible interpretations]

### Theoretical Implications
[How this advances theory]

### Practical Implications
[Detailed practical applications]

## Strengths and Limitations
### Methodological Strengths
- [Strength 1]
- [Strength 2]

### Limitations
- [Limitation 1 with impact]
- [Limitation 2 with impact]

## Future Research
[Detailed suggestions for future studies]

## Key References
[List of most important references cited]

## Technical Appendix
- [Important equations]
- [Technical definitions]
- [Specialized terminology]

Be EXTREMELY thorough. Include ALL details.
Target length: 3,000-5,000 words."""
}
```

**Ventajas**:
- ‚úÖ Prompts estructurados por nivel
- ‚úÖ Instrucciones claras sobre formato y longitud
- ‚úÖ Solicita informaci√≥n espec√≠fica seg√∫n secci√≥n

---

### Fase 4: Sistema de Resumen Comparativo Multi-Documento

```python
class MultiDocumentSummarizer:
    """Compara y sintetiza m√∫ltiples documentos."""

    def summarize_multiple(
        self,
        articles: List[Article],
        focus: str = "synthesis"  # synthesis | comparison | gaps
    ) -> str:
        """
        Genera resumen comparativo de m√∫ltiples documentos.

        Args:
            articles: Lista de art√≠culos a comparar
            focus: Tipo de an√°lisis
                - synthesis: Sintetiza ideas comunes
                - comparison: Compara diferencias
                - gaps: Identifica vac√≠os en literatura
        """

        # Extraer res√∫menes individuales
        individual_summaries = []
        for article in articles:
            summary = self._get_or_generate_summary(article, level="detailed")
            individual_summaries.append({
                'title': article.title,
                'authors': article.authors,
                'year': article.publication_year,
                'summary': summary
            })

        # An√°lisis comparativo
        comparative_summary = self._generate_comparative_analysis(
            individual_summaries,
            focus=focus
        )

        return comparative_summary

    def _generate_comparative_analysis(
        self,
        summaries: List[Dict],
        focus: str
    ) -> str:
        """Genera an√°lisis comparativo usando Groq."""

        prompt = self._build_comparative_prompt(summaries, focus)
        return self._call_groq(prompt)

    def _build_comparative_prompt(
        self,
        summaries: List[Dict],
        focus: str
    ) -> str:
        """Construye prompt para an√°lisis comparativo."""

        if focus == "synthesis":
            return f"""Analyze these {len(summaries)} research articles and create a SYNTHESIZED SUMMARY.

ARTICLES:
{self._format_summaries_for_prompt(summaries)}

CREATE A SYNTHESIS THAT:
1. Identifies common themes across all articles
2. Shows how findings complement each other
3. Builds a coherent narrative from multiple sources
4. Highlights consensus in the field

FORMAT:
# Synthesis of {len(summaries)} Research Articles

## Common Themes
[Identify 3-5 major themes present across articles]

## Methodological Approaches
[What methods are commonly used?]

## Convergent Findings
[What do most/all articles agree on?]

## Integrated Conclusions
[What can we conclude from the body of work?]

## Knowledge Gaps
[What questions remain unanswered?]

Length: 2-3 pages"""

        elif focus == "comparison":
            return f"""Compare and contrast these {len(summaries)} research articles.

ARTICLES:
{self._format_summaries_for_prompt(summaries)}

CREATE A COMPARATIVE ANALYSIS:
1. Show how articles differ in approach
2. Highlight contradictory findings
3. Explain different perspectives
4. Evaluate relative strengths

FORMAT:
# Comparative Analysis

## Research Approaches
| Article | Methodology | Sample | Key Innovation |
|---------|-------------|--------|----------------|
[Table comparing approaches]

## Divergent Findings
**Topic 1:**
- [Article A]: [Finding]
- [Article B]: [Different finding]
- [Analysis of difference]

## Strengths and Weaknesses
[Compare quality and rigor of each article]

## Recommendations
[Which article is most relevant for specific purposes?]

Length: 2-3 pages"""

        elif focus == "gaps":
            return f"""Identify research gaps based on these {len(summaries)} articles.

ARTICLES:
{self._format_summaries_for_prompt(summaries)}

IDENTIFY RESEARCH GAPS:

## What We Know (Covered Topics)
[Comprehensive list of what these articles cover]

## What's Missing (Research Gaps)
### Methodological Gaps
- [What methodologies haven't been used?]

### Population Gaps
- [What populations haven't been studied?]

### Contextual Gaps
- [What contexts/settings need research?]

### Theoretical Gaps
- [What theoretical perspectives are missing?]

## Future Research Priorities
[Ranked list of most important gaps to address]

## Proposed Research Questions
[Specific RQs to fill identified gaps]

Length: 2-3 pages"""
```

**Ventajas**:
- ‚úÖ Sintetiza m√∫ltiples documentos
- ‚úÖ Identifica patrones y gaps
- ‚úÖ √ötil para literatura reviews

---

## üìä Configuraci√≥n del Sistema

### Schema Actualizado

```python
# backend/app/core/schemas.py

class SummaryLevel(str, Enum):
    EXECUTIVE = "executive"    # 1 p√°gina
    DETAILED = "detailed"      # 3-4 p√°ginas
    EXHAUSTIVE = "exhaustive"  # 8-10 p√°ginas

class SummaryRequest(BaseModel):
    article_id: int
    level: SummaryLevel = SummaryLevel.DETAILED
    include_sections: Optional[List[str]] = None  # ['methodology', 'results']
    language: str = "es"  # es | en

class BatchSummaryRequest(BaseModel):
    article_ids: List[int]
    level: SummaryLevel = SummaryLevel.DETAILED
    comparison_mode: Optional[str] = None  # synthesis | comparison | gaps

class SummaryResponse(BaseModel):
    article_id: int
    title: str
    level: str
    summary: str
    word_count: int
    estimated_reading_time: int  # minutes
    sections_included: List[str]
    generated_at: datetime
```

---

### Configuraci√≥n Mejorada

```python
# backend/app/core/config.py

class SummarySettings:
    # L√≠mites por nivel
    LIMITS = {
        "executive": {
            "target_words": 500,
            "max_pages_to_process": 20,
            "chunk_size": 4000,
        },
        "detailed": {
            "target_words": 1800,
            "max_pages_to_process": 50,
            "chunk_size": 3000,
        },
        "exhaustive": {
            "target_words": 4000,
            "max_pages_to_process": 100,
            "chunk_size": 2500,
        }
    }

    # Groq settings
    GROQ_MODEL = "llama-3.3-70b-versatile"
    GROQ_TEMPERATURE = 0.3
    GROQ_MAX_TOKENS = 8000  # Aumentado para res√∫menes largos

    # Cache settings
    CACHE_SUMMARIES = True
    CACHE_TTL = 86400  # 24 horas
```

---

## üé® Interfaz de Usuario

### Componente de Configuraci√≥n de Resumen

```typescript
// frontend/src/components/ui/SummaryConfigModal.tsx

interface SummaryConfig {
  level: 'executive' | 'detailed' | 'exhaustive';
  sections?: string[];
  language: 'es' | 'en';
}

export const SummaryConfigModal = ({ articleIds, onGenerate }) => {
  const [config, setConfig] = useState<SummaryConfig>({
    level: 'detailed',
    language: 'es'
  });

  return (
    <Modal>
      <h2>Configurar Resumen</h2>

      {/* Selector de Nivel */}
      <div className="level-selector">
        <LevelOption
          name="Ejecutivo"
          description="Vista r√°pida - 1 p√°gina (~5 min lectura)"
          targetLength="500 palabras"
          selected={config.level === 'executive'}
          onClick={() => setConfig({...config, level: 'executive'})}
        />

        <LevelOption
          name="Detallado"
          description="Comprensi√≥n profunda - 3-4 p√°ginas (~15 min)"
          targetLength="1,800 palabras"
          selected={config.level === 'detailed'}
          onClick={() => setConfig({...config, level: 'detailed'})}
        />

        <LevelOption
          name="Exhaustivo"
          description="Extracci√≥n m√°xima - 8-10 p√°ginas (~40 min)"
          targetLength="4,000 palabras"
          selected={config.level === 'exhaustive'}
          onClick={() => setConfig({...config, level: 'exhaustive'})}
        />
      </div>

      {/* Selector de Secciones */}
      <div className="sections-selector">
        <h3>Secciones a Incluir (Opcional)</h3>
        <CheckboxGroup>
          <Checkbox label="Introducci√≥n" value="introduction" />
          <Checkbox label="Marco Te√≥rico" value="literature" />
          <Checkbox label="Metodolog√≠a" value="methodology" />
          <Checkbox label="Resultados" value="results" />
          <Checkbox label="Discusi√≥n" value="discussion" />
          <Checkbox label="Conclusiones" value="conclusions" />
        </CheckboxGroup>
      </div>

      {/* Estimaci√≥n */}
      <div className="estimate">
        <InfoBox>
          <p><strong>Tiempo estimado:</strong> {estimateTime(config)}</p>
          <p><strong>Longitud esperada:</strong> {estimateLength(config)}</p>
          <p><strong>Secciones:</strong> {getSectionsCount(config)}</p>
        </InfoBox>
      </div>

      <Button onClick={() => onGenerate(config)}>
        Generar Resumen {config.level}
      </Button>
    </Modal>
  );
};
```

### Visualizaci√≥n de Resumen

```typescript
// frontend/src/components/ui/SummaryDisplay.tsx

export const SummaryDisplay = ({ summary, config }) => {
  return (
    <div className="summary-display">
      {/* Header con metadatos */}
      <div className="summary-header">
        <h1>{summary.title}</h1>
        <div className="metadata">
          <Badge variant="primary">{config.level}</Badge>
          <span>{summary.word_count} palabras</span>
          <span>{summary.estimated_reading_time} min lectura</span>
          <span>{summary.generated_at}</span>
        </div>
      </div>

      {/* Tabla de Contenidos (solo para exhaustive) */}
      {config.level === 'exhaustive' && (
        <TableOfContents sections={summary.sections} />
      )}

      {/* Contenido del resumen con formato */}
      <div className="summary-content markdown-body">
        <ReactMarkdown>{summary.summary}</ReactMarkdown>
      </div>

      {/* Acciones */}
      <div className="summary-actions">
        <Button icon={<Download />}>Descargar PDF</Button>
        <Button icon={<Share />}>Compartir</Button>
        <Button icon={<Edit />}>Editar</Button>
        <Button icon={<Refresh />}>Regenerar</Button>
      </div>
    </div>
  );
};
```

---

## üìà Plan de Implementaci√≥n por Fases

### **Fase 1: Fundamentos** (1-2 semanas)
**Prioridad**: CR√çTICA

**Tareas**:
1. ‚úÖ Crear `DocumentStructureExtractor` para identificar secciones
2. ‚úÖ Implementar `ChunkedSummarizer` con map-reduce
3. ‚úÖ Actualizar schemas para niveles de resumen
4. ‚úÖ Crear nuevos prompts para Groq
5. ‚úÖ Aumentar l√≠mites de procesamiento

**Entregables**:
- Sistema que procesa documentos completos (no solo 5 p√°ginas)
- 3 niveles de resumen funcionales
- Tests unitarios

---

### **Fase 2: Interfaz de Usuario** (1 semana)
**Prioridad**: ALTA

**Tareas**:
1. ‚úÖ Crear `SummaryConfigModal` component
2. ‚úÖ Crear `SummaryDisplay` component
3. ‚úÖ Integrar con API existente
4. ‚úÖ Agregar indicadores de progreso
5. ‚úÖ Implementar cache de res√∫menes

**Entregables**:
- UI para seleccionar nivel de resumen
- Visualizaci√≥n mejorada de res√∫menes
- Feedback en tiempo real

---

### **Fase 3: Resumen Multi-Documento** (1-2 semanas)
**Prioridad**: MEDIA

**Tareas**:
1. ‚úÖ Implementar `MultiDocumentSummarizer`
2. ‚úÖ Crear prompts comparativos
3. ‚úÖ Agregar UI para selecci√≥n m√∫ltiple
4. ‚úÖ Implementar modos: synthesis, comparison, gaps

**Entregables**:
- Resumen comparativo funcional
- Detecci√≥n de gaps en literatura
- S√≠ntesis de m√∫ltiples estudios

---

### **Fase 4: Optimizaciones** (1 semana)
**Prioridad**: MEDIA

**Tareas**:
1. ‚úÖ Implementar cache de res√∫menes
2. ‚úÖ Optimizar llamadas a Groq (batching)
3. ‚úÖ Agregar workers para procesamiento async
4. ‚úÖ Implementar rate limiting
5. ‚úÖ Mejorar manejo de errores

**Entregables**:
- Sistema m√°s r√°pido y eficiente
- Mejor experiencia de usuario
- Menos costos de API

---

### **Fase 5: Features Avanzadas** (2 semanas)
**Prioridad**: BAJA (futuro)

**Tareas**:
1. üîÆ Soporte para m√°s idiomas
2. üîÆ Res√∫menes personalizables por plantillas
3. üîÆ Extracci√≥n de figuras y tablas
4. üîÆ Generaci√≥n de presentaciones autom√°ticas
5. üîÆ Integraci√≥n con sistemas de notas (Notion, Obsidian)

---

## üí∞ Estimaci√≥n de Costos (Groq API)

### Costos Actuales
```
Resumen actual: 5 oraciones √ó 35 palabras = ~175 tokens
Costo por resumen: ~$0.001
```

### Costos Nuevos
```
Nivel Ejecutivo: ~500 palabras = ~700 tokens
Costo: ~$0.003

Nivel Detallado: ~1,800 palabras = ~2,500 tokens
Costo: ~$0.008

Nivel Exhaustivo: ~4,000 palabras = ~5,500 tokens
Costo: ~$0.018

Resumen Multi-doc (3 art√≠culos): ~$0.024
```

### Optimizaciones de Costo
1. **Cache agresivo**: 90% de hits esperado
2. **Batching**: Reducci√≥n de 30% en llamadas
3. **Smart chunking**: Procesar solo secciones relevantes
4. **Fallback a local**: Usar TF-IDF para nivel ejecutivo

**Costo mensual estimado** (100 usuarios activos):
- Sin optimizaciones: ~$150/mes
- Con optimizaciones: ~$45/mes

---

## üéØ M√©tricas de √âxito

### T√©cnicas
- ‚úÖ Procesar documentos de hasta 100 p√°ginas
- ‚úÖ Generar res√∫menes de 500-5,000 palabras
- ‚úÖ Tiempo de procesamiento < 3 minutos
- ‚úÖ 95% de √©xito en extracci√≥n de secciones

### Experiencia de Usuario
- ‚úÖ Satisfacci√≥n con res√∫menes: >4.5/5
- ‚úÖ Tiempo ahorrado: >80% vs leer completo
- ‚úÖ Precisi√≥n percibida: >90%
- ‚úÖ Uso regular: >70% usuarios activos

### Negocio
- ‚úÖ Reducir tiempo de revisi√≥n de literatura en 60%
- ‚úÖ Aumentar n√∫mero de art√≠culos analizados por usuario en 3x
- ‚úÖ ROI positivo en 3 meses

---

## üöÄ Quick Wins (Implementaci√≥n Inmediata)

### 1. Aumentar l√≠mites (30 minutos)
```python
# Cambiar en summarizer.py
self.max_input_chars = 50000  # Era 12000
max_pages = 30  # Era 5
```

### 2. Mejorar prompt de Groq (1 hora)
```python
# Cambiar prompt actual para ser m√°s detallado
"Create a comprehensive 1,500-word summary including: introduction, methodology, results, and conclusions. Be thorough and academic."
```

### 3. Agregar selector de longitud en UI (2 horas)
```typescript
<Select
  label="Longitud del resumen"
  options={[
    { value: "short", label: "Corto (500 palabras)" },
    { value: "medium", label: "Medio (1,500 palabras)" },
    { value: "long", label: "Largo (3,000+ palabras)" }
  ]}
/>
```

---

## üìù Pr√≥ximos Pasos Inmediatos

### Esta Semana
1. ‚úÖ Implementar `DocumentStructureExtractor`
2. ‚úÖ Actualizar l√≠mites de procesamiento
3. ‚úÖ Crear prompts mejorados
4. ‚úÖ Agregar configuraci√≥n por niveles

### Pr√≥xima Semana
1. ‚úÖ Implementar `ChunkedSummarizer`
2. ‚úÖ Crear UI para niveles de resumen
3. ‚úÖ Testing exhaustivo
4. ‚úÖ Deploy a producci√≥n

---

## ‚úÖ Recomendaciones del Senior Developer

### Arquitectura
1. **Usar Map-Reduce**: Es la √∫nica forma de procesar documentos grandes eficientemente
2. **Extracci√≥n de secciones**: Crucial para res√∫menes estructurados
3. **Cache inteligente**: Evitar reprocesar documentos
4. **Async processing**: Los res√∫menes largos deben ser as√≠ncronos

### Calidad
1. **Prompts detallados**: Groq necesita instrucciones muy espec√≠ficas
2. **Overlap en chunks**: Mantiene coherencia narrativa
3. **Post-processing**: Limpieza y formato del output
4. **Validaci√≥n**: Verificar que el resumen tenga sentido

### UX
1. **Estimaciones claras**: Mostrar tiempo y longitud esperados
2. **Progreso en tiempo real**: Para res√∫menes largos
3. **Niveles claros**: Explicar diferencias entre niveles
4. **Edici√≥n**: Permitir que usuarios refinen res√∫menes

### Costos
1. **Cache primero**: Implementar antes que nada
2. **Batching**: Agrupar llamadas a API
3. **Fallback local**: TF-IDF para casos simples
4. **Monitoreo**: Alertas si costos suben

---

## üìö Referencias T√©cnicas

- [Groq API Documentation](https://console.groq.com/docs)
- [Map-Reduce for Summarization (LangChain)](https://python.langchain.com/docs/use_cases/summarization)
- [PDF Text Extraction Best Practices](https://pymupdf.readthedocs.io/)
- [TF-IDF for Extractive Summarization](https://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting)

---

**Documento creado por**: Senior Developer
**Fecha**: Noviembre 2025
**Estado**: PLAN APROBADO - LISTO PARA IMPLEMENTAR
**Pr√≥xima revisi√≥n**: Despu√©s de Fase 1
